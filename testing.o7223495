## Hosts assigned to job 7223495.1:
##
## db05gpu8.arc4.leeds.ac.uk 10 slots
##
## Resources granted:
##
## h_vmem = 5153960755 (per slot)
## h_rt   = 00:30:00
## disk   = 1G (per slot)

[2025-01-20 10:03:06] arg_name: arguments
[2025-01-20 10:03:06] filename: arguments
[2025-01-20 10:03:06] Namespace(seed=2048, mode='train', analysis_type='variable_time', subanalysis_type='B1_1_FNO_attention', experiment='run_4_new_attention_3', test_only_path='', test_only_protocol_no=1, test_only_epoch_index=-1, dataset_name='B1', dataset_train_path=None, dataset_valid_path=None, dataset_test_path=None, t_resolution=None, t_resolution_train=None, t_resolution_test=None, t_resolution_valid=None, x_resolution=None, timestamps=None, timestamps_test=None, timestamps_valid=None, no_parameters=2, n_train=32, n_test=32, batch_size_train=32, batch_size_test=32, time_stamps=None, time_stamps_test=None, root_dir=None, current_dir_path='/nobackup/scoc/variable_autoregression', model_type='FNO1d_t_attention', fno_hidden_dim=32, fno_hidden_layers=2, fno_modes=16, pretrained_model='', model_initialise_type='random', time_prediction='variable', time_conditioning='attention', predict_difference=False, n_tsamples=[], time_sampling_type=None, dt_step=1, input_time_stamps=10, output_time_stamps=10, next_input_time_stamps=None, initialise_optimiser=[], optimizer_type=None, learning_rate=[], weight_decay=[], min_learning_rate=[], sheduler_type=[], sheduler_step=[], sheduler_gamma=[], sheduler_change=[], cos_anneal_T_max=[], new_training=True, training_protocol_type='training_loop_by_batch_first', number_of_training_protocol=1, epochs=[], iter_per_epochs=[], training_loop='random_time_sampling', loss_train_type='l2', loss_test_type='l2', dynamic_loss_weight_per_fpass=None, dynamic_loss_weight_per_fpass_constant_parameter=None, dynamic_loss_weight_per_fpass_reversed=None, dynamic_loss_weight_per_tstamp=None, dynamic_loss_weight_per_tstamp_constant_parameter=None, dynamic_loss_weight_per_fpass_type=None, epoch_save_interval=25, epoch_print_interval=5, result_save_path='', current_result_save_path='', current_date_save_path='', horizon=[1], horizon_type='constant', random_horizon=False, push_forward=None, push_forward_parameter=None, push_forward_parameter_random=None, noise=False, noise_std=0.01, norm=False, normalise_parameters=True, time_sampling_choice=2, optimiser_type=[], training_protocols=[{'epochs': 100, 'iter_per_epochs': 250, 'no_input_tspace': 1, 'horizon': [3], 'random_horizon': False, 'push_forward': False, 'push_forward_parameter_random': False, 'push_forward_parameter': 1, 'dynamic_loss_weight_per_fpass': False, 'dynamic_loss_weight_per_fpass_type': 'global', 'dynamic_loss_weight_per_fpass_constant_parameter': 0.5, 'dynamic_loss_weight_per_tstamp': False, 'dynamic_loss_weight_per_tstamp_constant_parameter': 0.8, 'dynamic_loss_weight_per_fpass_reversed': False, 'noise': False, 'noise_std': 0.01, 'norm': False, 'initialise_optimiser': True, 'optimiser_type': 'adam', 'sheduler_type': 'steplr', 'sheduler_change': 'epoch', 'cos_anneal_T_max': 5000, 'learning_rate': 0.001, 'min_learning_rate': 1e-05, 'sheduler_step': 2, 'sheduler_gamma': 0.95, 'weight_decay': 1e-05, 'input_sampler_type': [1], 'input_sampler_type_dt': [1], 'output_sampler_type': [1]}])
[2025-01-20 10:03:11] Minibatches for train: 1
[2025-01-20 10:03:11] Minibatches for val: 1
[2025-01-20 10:03:11] Minibatches for test: 1
[2025-01-20 10:03:11] Folder 'result' already exists!
[2025-01-20 10:03:11] Folder 'B1' already exists!
[2025-01-20 10:03:11] Folder 'variable_time' already exists!
[2025-01-20 10:03:11] Folder 'B1_1_FNO_attention' already exists!
[2025-01-20 10:03:11] Folder 'run_4_new_attention_3' already exists!
[2025-01-20 10:03:11] New Training
[2025-01-20 10:03:11] Model with Random Intitialisation
[2025-01-20 10:03:11] model FNO1d_t_attention(
  (fc0): Linear(in_features=11, out_features=32, bias=True)
  (t_embed_high_in): Linear(in_features=11, out_features=32, bias=True)
  (t_embed_high_out): Linear(in_features=11, out_features=32, bias=True)
  (time_embed_x): Sequential(
    (0): Linear(in_features=1, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=256, bias=True)
  )
  (time_embed_y): Sequential(
    (0): Linear(in_features=1, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=256, bias=True)
  )
  (conv0): SpectralConv1d()
  (attend_0): SelfAttention(
    (wq): Linear(in_features=32, out_features=32, bias=False)
    (wk): Linear(in_features=32, out_features=32, bias=False)
    (wv): Linear(in_features=32, out_features=32, bias=False)
    (softmax): Softmax(dim=-1)
  )
  (conv1): SpectralConv1d()
  (attend_1): SelfAttention(
    (wq): Linear(in_features=32, out_features=32, bias=False)
    (wk): Linear(in_features=32, out_features=32, bias=False)
    (wv): Linear(in_features=32, out_features=32, bias=False)
    (softmax): Softmax(dim=-1)
  )
  (conv2): SpectralConv1d()
  (attend_2): SelfAttention(
    (wq): Linear(in_features=32, out_features=32, bias=False)
    (wk): Linear(in_features=32, out_features=32, bias=False)
    (wv): Linear(in_features=32, out_features=32, bias=False)
    (softmax): Softmax(dim=-1)
  )
  (conv3): SpectralConv1d()
  (attend_3): SelfAttention(
    (wq): Linear(in_features=32, out_features=32, bias=False)
    (wk): Linear(in_features=32, out_features=32, bias=False)
    (wv): Linear(in_features=32, out_features=32, bias=False)
    (softmax): Softmax(dim=-1)
  )
  (w0): Conv1d(32, 32, kernel_size=(1,), stride=(1,))
  (w1): Conv1d(32, 32, kernel_size=(1,), stride=(1,))
  (w2): Conv1d(32, 32, kernel_size=(1,), stride=(1,))
  (w3): Conv1d(32, 32, kernel_size=(1,), stride=(1,))
  (fc1): Linear(in_features=32, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=10, bias=True)
)
[2025-01-20 10:03:11] Number of model parameters_complex_function: 220810
[2025-01-20 10:03:11] Number of model parameters_numbers: 155274
[2025-01-20 10:03:11] Namespace(seed=2048, mode='train', analysis_type='variable_time', subanalysis_type='B1_1_FNO_attention', experiment='run_4_new_attention_3', test_only_path='', test_only_protocol_no=1, test_only_epoch_index=-1, dataset_name='B1', dataset_train_path='/nobackup/scoc/variable_autoregression/dataset/data/B1/1D_Burgers_Sols_Nu0.01_K1_N2_Sa2100.npy', dataset_valid_path='/nobackup/scoc/variable_autoregression/dataset/data/B1/1D_Burgers_Sols_Nu0.01_K1_N2_Sa2100.npy', dataset_test_path='/nobackup/scoc/variable_autoregression/dataset/data/B1/1D_Burgers_Sols_Nu0.01_K1_N2_Sa2100.npy', t_resolution=201, t_resolution_train=201, t_resolution_test=201, t_resolution_valid=201, x_resolution=256, timestamps=[0.0, 0.004, 0.008, 0.012, 0.016, 0.02, 0.024, 0.028, 0.032, 0.036000000000000004, 0.04, 0.044, 0.048, 0.052000000000000005, 0.056, 0.06, 0.064, 0.068, 0.07200000000000001, 0.076, 0.08, 0.084, 0.088, 0.092, 0.096, 0.1, 0.10400000000000001, 0.108, 0.112, 0.116, 0.12, 0.124, 0.128, 0.132, 0.136, 0.14, 0.14400000000000002, 0.148, 0.152, 0.156, 0.16, 0.164, 0.168, 0.17200000000000001, 0.176, 0.18, 0.184, 0.188, 0.192, 0.196, 0.2, 0.20400000000000001, 0.20800000000000002, 0.212, 0.216, 0.22, 0.224, 0.228, 0.232, 0.23600000000000002, 0.24, 0.244, 0.248, 0.252, 0.256, 0.26, 0.264, 0.268, 0.272, 0.276, 0.28, 0.28400000000000003, 0.28800000000000003, 0.292, 0.296, 0.3, 0.304, 0.308, 0.312, 0.316, 0.32, 0.324, 0.328, 0.332, 0.336, 0.34, 0.34400000000000003, 0.34800000000000003, 0.352, 0.356, 0.36, 0.364, 0.368, 0.372, 0.376, 0.38, 0.384, 0.388, 0.392, 0.396, 0.4, 0.404, 0.40800000000000003, 0.41200000000000003, 0.41600000000000004, 0.42, 0.424, 0.428, 0.432, 0.436, 0.44, 0.444, 0.448, 0.452, 0.456, 0.46, 0.464, 0.468, 0.47200000000000003, 0.47600000000000003, 0.48, 0.484, 0.488, 0.492, 0.496, 0.5, 0.504, 0.508, 0.512, 0.516, 0.52, 0.524, 0.528, 0.532, 0.536, 0.54, 0.544, 0.548, 0.552, 0.556, 0.56, 0.5640000000000001, 0.5680000000000001, 0.5720000000000001, 0.5760000000000001, 0.58, 0.584, 0.588, 0.592, 0.596, 0.6, 0.604, 0.608, 0.612, 0.616, 0.62, 0.624, 0.628, 0.632, 0.636, 0.64, 0.644, 0.648, 0.652, 0.656, 0.66, 0.664, 0.668, 0.672, 0.676, 0.68, 0.684, 0.6880000000000001, 0.6920000000000001, 0.6960000000000001, 0.7000000000000001, 0.704, 0.708, 0.712, 0.716, 0.72, 0.724, 0.728, 0.732, 0.736, 0.74, 0.744, 0.748, 0.752, 0.756, 0.76, 0.764, 0.768, 0.772, 0.776, 0.78, 0.784, 0.788, 0.792, 0.796, 0.8], timestamps_test=[0.0, 0.004, 0.008, 0.012, 0.016, 0.02, 0.024, 0.028, 0.032, 0.036000000000000004, 0.04, 0.044, 0.048, 0.052000000000000005, 0.056, 0.06, 0.064, 0.068, 0.07200000000000001, 0.076, 0.08, 0.084, 0.088, 0.092, 0.096, 0.1, 0.10400000000000001, 0.108, 0.112, 0.116, 0.12, 0.124, 0.128, 0.132, 0.136, 0.14, 0.14400000000000002, 0.148, 0.152, 0.156, 0.16, 0.164, 0.168, 0.17200000000000001, 0.176, 0.18, 0.184, 0.188, 0.192, 0.196, 0.2, 0.20400000000000001, 0.20800000000000002, 0.212, 0.216, 0.22, 0.224, 0.228, 0.232, 0.23600000000000002, 0.24, 0.244, 0.248, 0.252, 0.256, 0.26, 0.264, 0.268, 0.272, 0.276, 0.28, 0.28400000000000003, 0.28800000000000003, 0.292, 0.296, 0.3, 0.304, 0.308, 0.312, 0.316, 0.32, 0.324, 0.328, 0.332, 0.336, 0.34, 0.34400000000000003, 0.34800000000000003, 0.352, 0.356, 0.36, 0.364, 0.368, 0.372, 0.376, 0.38, 0.384, 0.388, 0.392, 0.396, 0.4, 0.404, 0.40800000000000003, 0.41200000000000003, 0.41600000000000004, 0.42, 0.424, 0.428, 0.432, 0.436, 0.44, 0.444, 0.448, 0.452, 0.456, 0.46, 0.464, 0.468, 0.47200000000000003, 0.47600000000000003, 0.48, 0.484, 0.488, 0.492, 0.496, 0.5, 0.504, 0.508, 0.512, 0.516, 0.52, 0.524, 0.528, 0.532, 0.536, 0.54, 0.544, 0.548, 0.552, 0.556, 0.56, 0.5640000000000001, 0.5680000000000001, 0.5720000000000001, 0.5760000000000001, 0.58, 0.584, 0.588, 0.592, 0.596, 0.6, 0.604, 0.608, 0.612, 0.616, 0.62, 0.624, 0.628, 0.632, 0.636, 0.64, 0.644, 0.648, 0.652, 0.656, 0.66, 0.664, 0.668, 0.672, 0.676, 0.68, 0.684, 0.6880000000000001, 0.6920000000000001, 0.6960000000000001, 0.7000000000000001, 0.704, 0.708, 0.712, 0.716, 0.72, 0.724, 0.728, 0.732, 0.736, 0.74, 0.744, 0.748, 0.752, 0.756, 0.76, 0.764, 0.768, 0.772, 0.776, 0.78, 0.784, 0.788, 0.792, 0.796, 0.8], timestamps_valid=[0.0, 0.004, 0.008, 0.012, 0.016, 0.02, 0.024, 0.028, 0.032, 0.036000000000000004, 0.04, 0.044, 0.048, 0.052000000000000005, 0.056, 0.06, 0.064, 0.068, 0.07200000000000001, 0.076, 0.08, 0.084, 0.088, 0.092, 0.096, 0.1, 0.10400000000000001, 0.108, 0.112, 0.116, 0.12, 0.124, 0.128, 0.132, 0.136, 0.14, 0.14400000000000002, 0.148, 0.152, 0.156, 0.16, 0.164, 0.168, 0.17200000000000001, 0.176, 0.18, 0.184, 0.188, 0.192, 0.196, 0.2, 0.20400000000000001, 0.20800000000000002, 0.212, 0.216, 0.22, 0.224, 0.228, 0.232, 0.23600000000000002, 0.24, 0.244, 0.248, 0.252, 0.256, 0.26, 0.264, 0.268, 0.272, 0.276, 0.28, 0.28400000000000003, 0.28800000000000003, 0.292, 0.296, 0.3, 0.304, 0.308, 0.312, 0.316, 0.32, 0.324, 0.328, 0.332, 0.336, 0.34, 0.34400000000000003, 0.34800000000000003, 0.352, 0.356, 0.36, 0.364, 0.368, 0.372, 0.376, 0.38, 0.384, 0.388, 0.392, 0.396, 0.4, 0.404, 0.40800000000000003, 0.41200000000000003, 0.41600000000000004, 0.42, 0.424, 0.428, 0.432, 0.436, 0.44, 0.444, 0.448, 0.452, 0.456, 0.46, 0.464, 0.468, 0.47200000000000003, 0.47600000000000003, 0.48, 0.484, 0.488, 0.492, 0.496, 0.5, 0.504, 0.508, 0.512, 0.516, 0.52, 0.524, 0.528, 0.532, 0.536, 0.54, 0.544, 0.548, 0.552, 0.556, 0.56, 0.5640000000000001, 0.5680000000000001, 0.5720000000000001, 0.5760000000000001, 0.58, 0.584, 0.588, 0.592, 0.596, 0.6, 0.604, 0.608, 0.612, 0.616, 0.62, 0.624, 0.628, 0.632, 0.636, 0.64, 0.644, 0.648, 0.652, 0.656, 0.66, 0.664, 0.668, 0.672, 0.676, 0.68, 0.684, 0.6880000000000001, 0.6920000000000001, 0.6960000000000001, 0.7000000000000001, 0.704, 0.708, 0.712, 0.716, 0.72, 0.724, 0.728, 0.732, 0.736, 0.74, 0.744, 0.748, 0.752, 0.756, 0.76, 0.764, 0.768, 0.772, 0.776, 0.78, 0.784, 0.788, 0.792, 0.796, 0.8], no_parameters=2, n_train=32, n_test=32, batch_size_train=32, batch_size_test=32, time_stamps=None, time_stamps_test=None, root_dir=None, current_dir_path='/nobackup/scoc/variable_autoregression', model_type='FNO1d_t_attention', fno_hidden_dim=32, fno_hidden_layers=2, fno_modes=16, pretrained_model='', model_initialise_type='random', time_prediction='variable', time_conditioning='attention', predict_difference=False, n_tsamples=[], time_sampling_type=None, dt_step=1, input_time_stamps=10, output_time_stamps=10, next_input_time_stamps=None, initialise_optimiser=[True], optimizer_type=None, learning_rate=[0.001], weight_decay=[1e-05], min_learning_rate=[1e-05], sheduler_type=['steplr'], sheduler_step=[2], sheduler_gamma=[0.95], sheduler_change=['epoch'], cos_anneal_T_max=[5000], new_training=True, training_protocol_type='training_loop_by_batch_first', number_of_training_protocol=1, epochs=[100], iter_per_epochs=[250], training_loop='random_time_sampling', loss_train_type='l2', loss_test_type='l2', dynamic_loss_weight_per_fpass=[False], dynamic_loss_weight_per_fpass_constant_parameter=[0.5], dynamic_loss_weight_per_fpass_reversed=[False], dynamic_loss_weight_per_tstamp=[False], dynamic_loss_weight_per_tstamp_constant_parameter=[0.8], dynamic_loss_weight_per_fpass_type=['global'], epoch_save_interval=25, epoch_print_interval=5, result_save_path='/nobackup/scoc/variable_autoregression/result/B1/variable_time/B1_1_FNO_attention', current_result_save_path='/nobackup/scoc/variable_autoregression/result/B1/variable_time/B1_1_FNO_attention/run_4_new_attention_3', current_date_save_path='', horizon=[[3]], horizon_type='constant', random_horizon=[False], push_forward=[False], push_forward_parameter=[1], push_forward_parameter_random=[False], noise=[False], noise_std=[0.01], norm=[False], normalise_parameters=True, time_sampling_choice=2, optimiser_type=['adam'], training_protocols=[{'epochs': 100, 'iter_per_epochs': 250, 'no_input_tspace': 1, 'horizon': [3], 'random_horizon': False, 'push_forward': False, 'push_forward_parameter_random': False, 'push_forward_parameter': 1, 'dynamic_loss_weight_per_fpass': False, 'dynamic_loss_weight_per_fpass_type': 'global', 'dynamic_loss_weight_per_fpass_constant_parameter': 0.5, 'dynamic_loss_weight_per_tstamp': False, 'dynamic_loss_weight_per_tstamp_constant_parameter': 0.8, 'dynamic_loss_weight_per_fpass_reversed': False, 'noise': False, 'noise_std': 0.01, 'norm': False, 'initialise_optimiser': True, 'optimiser_type': 'adam', 'sheduler_type': 'steplr', 'sheduler_change': 'epoch', 'cos_anneal_T_max': 5000, 'learning_rate': 0.001, 'min_learning_rate': 1e-05, 'sheduler_step': 2, 'sheduler_gamma': 0.95, 'weight_decay': 1e-05, 'input_sampler_type': [1], 'input_sampler_type_dt': [1], 'output_sampler_type': [1]}], no_input_tspace=[1], input_sampler_type=[[1]], input_sampler_type_dt=[[1]], output_sampler_type=[[1]])
[2025-01-20 10:03:11] dynamic_loss_weight_per_fpass: False
[2025-01-20 10:03:11] scheduler_change: epoch
max horizon -> 19
[2025-01-20 10:03:11] Input multistep: 10
[2025-01-20 10:03:11] Output multistep: 10
[2025-01-20 10:03:11] horizon: [3]
[2025-01-20 10:03:11] Number of tsamples : [40]
[2025-01-20 10:03:11] Number of iteration per tsamples: 250
[2025-01-20 10:03:11] total iteration: 25000
[2025-01-20 10:03:11] noise:  False
[2025-01-20 10:03:11] noise_std: 0.01
[2025-01-20 10:03:11] norm: False
[2025-01-20 10:03:11] dt_step: 1
[2025-01-20 10:03:11] dynamic_loss_weight_per_fpass: False
[2025-01-20 10:03:11] dynamic_loss_weight_per_tstamp: False
[2025-01-20 10:03:11] push_forward: False
[2025-01-20 10:03:11] scheduler: <torch.optim.lr_scheduler.StepLR object at 0x2ae13c65e580>
[2025-01-20 10:03:11] sheduler_change: epoch
[2025-01-20 10:03:11] horizon: [3]
[2025-01-20 10:03:11] predict_difference: False
[2025-01-20 10:03:13] horizon --> 3
[2025-01-20 10:03:13] horizon_grad --> 3
[2025-01-20 10:03:13] x --> (0, 10)
[2025-01-20 10:03:13] x_t --> tensor([[ 98, 105, 105, 106, 111],
        [ 61,  64,  65,  69,  72],
        [ 34,  36,  42,  53,  62]])
[2025-01-20 10:03:13] y --> (10, 20) 
[2025-01-20 10:03:13] y_t --> tensor([[120, 120, 124, 126, 128],
        [ 76,  78,  83,  87,  92],
        [ 88,  97, 100, 100, 107]]) 
[2025-01-20 10:03:14] f_pass_weights[0] ->, tensor([1., 1., 1.], device='cuda:0')
[2025-01-20 10:03:14] loss ->, 373.932861328125
[2025-01-20 10:03:14] 

[2025-01-20 10:03:14] horizon --> 3
[2025-01-20 10:03:14] horizon_grad --> 3
[2025-01-20 10:03:14] x --> (10, 20)
[2025-01-20 10:03:14] x_t --> tensor([[120, 120, 124, 126, 128],
        [ 76,  78,  83,  87,  92],
        [ 88,  97, 100, 100, 107]])
[2025-01-20 10:03:14] y --> (20, 30) 
[2025-01-20 10:03:14] y_t --> tensor([[147, 147, 147, 148, 149],
        [100, 101, 102, 107, 107],
        [138, 138, 146, 150, 154]]) 
[2025-01-20 10:03:14] f_pass_weights[1] ->, tensor([1., 1., 1.], device='cuda:0')
[2025-01-20 10:03:14] loss ->, 758.7816162109375
[2025-01-20 10:03:14] 

[2025-01-20 10:03:14] horizon --> 3
[2025-01-20 10:03:14] horizon_grad --> 3
[2025-01-20 10:03:14] x --> (20, 30)
[2025-01-20 10:03:14] x_t --> tensor([[147, 147, 147, 148, 149],
        [100, 101, 102, 107, 107],
        [138, 138, 146, 150, 154]])
[2025-01-20 10:03:14] y --> (30, 40) 
[2025-01-20 10:03:14] y_t --> tensor([[154, 155, 155, 156, 173],
        [115, 116, 116, 117, 117],
        [165, 172, 172, 174, 176]]) 
[2025-01-20 10:03:14] f_pass_weights[2] ->, tensor([1., 1., 1.], device='cuda:0')
[2025-01-20 10:03:14] loss ->, 1154.79443359375
[2025-01-20 10:03:14] 

[2025-01-20 10:03:15] horizon --> 3
[2025-01-20 10:03:15] horizon_grad --> 3
[2025-01-20 10:03:15] x --> (0, 10)
[2025-01-20 10:03:15] x_t --> tensor([[142, 146, 149, 149, 149],
        [ 82,  82,  85,  87,  87],
        [  7,  13,  16,  16,  19]])
[2025-01-20 10:03:15] y --> (10, 20) 
[2025-01-20 10:03:15] y_t --> tensor([[156, 160, 162, 163, 163],
        [103, 103, 104, 104, 108],
        [ 26,  29,  30,  38,  41]]) 
[2025-01-20 10:03:15] f_pass_weights[0] ->, tensor([1., 1., 1.], device='cuda:0')
[2025-01-20 10:03:15] loss ->, 351.57745361328125
[2025-01-20 10:03:15] 

[2025-01-20 10:03:15] horizon --> 3
[2025-01-20 10:03:15] horizon_grad --> 3
[2025-01-20 10:03:15] x --> (10, 20)
[2025-01-20 10:03:15] x_t --> tensor([[156, 160, 162, 163, 163],
        [103, 103, 104, 104, 108],
        [ 26,  29,  30,  38,  41]])
[2025-01-20 10:03:15] y --> (20, 30) 
[2025-01-20 10:03:15] y_t --> tensor([[171, 172, 174, 174, 175],
        [120, 124, 125, 125, 127],
        [ 71,  72,  75,  84,  85]]) 
[2025-01-20 10:03:15] f_pass_weights[1] ->, tensor([1., 1., 1.], device='cuda:0')
[2025-01-20 10:03:15] loss ->, 710.5718994140625
[2025-01-20 10:03:15] 

[2025-01-20 10:03:15] horizon --> 3
[2025-01-20 10:03:15] horizon_grad --> 3
[2025-01-20 10:03:15] x --> (20, 30)
[2025-01-20 10:03:15] x_t --> tensor([[171, 172, 174, 174, 175],
        [120, 124, 125, 125, 127],
        [ 71,  72,  75,  84,  85]])
[2025-01-20 10:03:15] y --> (30, 40) 
[2025-01-20 10:03:15] y_t --> tensor([[184, 192, 192, 193, 194],
        [147, 150, 150, 155, 156],
        [112, 118, 119, 128, 145]]) 
[2025-01-20 10:03:15] f_pass_weights[2] ->, tensor([1., 1., 1.], device='cuda:0')
[2025-01-20 10:03:15] loss ->, 1078.111083984375
[2025-01-20 10:03:15] 

[2025-01-20 10:03:15] horizon --> 3
[2025-01-20 10:03:15] horizon_grad --> 3
[2025-01-20 10:03:15] x --> (0, 10)
[2025-01-20 10:03:15] x_t --> tensor([[ 68,  69,  72,  72,  73],
        [132, 137, 139, 140, 141],
        [ 20,  31,  42,  50,  53]])
[2025-01-20 10:03:15] y --> (10, 20) 
[2025-01-20 10:03:15] y_t --> tensor([[ 84,  88,  95,  96, 101],
        [154, 155, 155, 157, 158],
        [ 70,  71,  72,  75,  81]]) 
[2025-01-20 10:03:15] f_pass_weights[0] ->, tensor([1., 1., 1.], device='cuda:0')
[2025-01-20 10:03:15] loss ->, 337.39654541015625
[2025-01-20 10:03:15] 

[2025-01-20 10:03:15] horizon --> 3
[2025-01-20 10:03:15] horizon_grad --> 3
[2025-01-20 10:03:15] x --> (10, 20)
[2025-01-20 10:03:15] x_t --> tensor([[ 84,  88,  95,  96, 101],
        [154, 155, 155, 157, 158],
        [ 70,  71,  72,  75,  81]])
[2025-01-20 10:03:15] y --> (20, 30) 
[2025-01-20 10:03:15] y_t --> tensor([[111, 113, 130, 137, 141],
        [165, 168, 168, 169, 171],
        [102, 103, 107, 111, 113]]) 
[2025-01-20 10:03:15] f_pass_weights[1] ->, tensor([1., 1., 1.], device='cuda:0')
[2025-01-20 10:03:15] loss ->, 679.1290283203125
[2025-01-20 10:03:15] 

[2025-01-20 10:03:15] horizon --> 3
[2025-01-20 10:03:15] horizon_grad --> 3
[2025-01-20 10:03:15] x --> (20, 30)
[2025-01-20 10:03:15] x_t --> tensor([[111, 113, 130, 137, 141],
        [165, 168, 168, 169, 171],
        [102, 103, 107, 111, 113]])
[2025-01-20 10:03:15] y --> (30, 40) 
[2025-01-20 10:03:15] y_t --> tensor([[157, 170, 171, 171, 177],
        [180, 184, 186, 186, 186],
        [126, 127, 133, 150, 154]]) 
[2025-01-20 10:03:15] f_pass_weights[2] ->, tensor([1., 1., 1.], device='cuda:0')
[2025-01-20 10:03:15] loss ->, 1025.68115234375
[2025-01-20 10:03:15] 

[2025-01-20 10:03:15] horizon --> 3
[2025-01-20 10:03:15] horizon_grad --> 3
[2025-01-20 10:03:15] x --> (0, 10)
[2025-01-20 10:03:15] x_t --> tensor([[ 26,  31,  44,  65,  66],
        [151, 154, 155, 156, 156],
        [ 75,  76,  77,  78,  80]])
[2025-01-20 10:03:15] y --> (10, 20) 
[2025-01-20 10:03:15] y_t --> tensor([[104, 105, 105, 109, 117],
        [166, 167, 168, 168, 168],
        [ 87,  88,  88,  89,  89]]) 
[2025-01-20 10:03:15] f_pass_weights[0] ->, tensor([1., 1., 1.], device='cuda:0')
[2025-01-20 10:03:15] loss ->, 330.9117126464844
[2025-01-20 10:03:15] 

[2025-01-20 10:03:15] horizon --> 3
[2025-01-20 10:03:15] horizon_grad --> 3
[2025-01-20 10:03:15] x --> (10, 20)
[2025-01-20 10:03:15] x_t --> tensor([[104, 105, 105, 109, 117],
        [166, 167, 168, 168, 168],
        [ 87,  88,  88,  89,  89]])
[2025-01-20 10:03:15] y --> (20, 30) 
[2025-01-20 10:03:15] y_t --> tensor([[136, 141, 141, 145, 147],
        [173, 173, 174, 175, 175],
        [ 93,  93,  95,  95,  98]]) 
[2025-01-20 10:03:15] f_pass_weights[1] ->, tensor([1., 1., 1.], device='cuda:0')
[2025-01-20 10:03:15] loss ->, 664.8115234375
[2025-01-20 10:03:15] 

[2025-01-20 10:03:15] horizon --> 3
[2025-01-20 10:03:15] horizon_grad --> 3
[2025-01-20 10:03:15] x --> (20, 30)
[2025-01-20 10:03:15] x_t --> tensor([[136, 141, 141, 145, 147],
        [173, 173, 174, 175, 175],
        [ 93,  93,  95,  95,  98]])
[2025-01-20 10:03:15] y --> (30, 40) 
[2025-01-20 10:03:15] y_t --> tensor([[159, 159, 161, 174, 175],
        [184, 186, 186, 187, 188],
        [105, 105, 106, 107, 109]]) 
[2025-01-20 10:03:15] f_pass_weights[2] ->, tensor([1., 1., 1.], device='cuda:0')
[2025-01-20 10:03:15] loss ->, 1001.9271240234375
[2025-01-20 10:03:15] 

[2025-01-20 10:03:15] horizon --> 3
[2025-01-20 10:03:15] horizon_grad --> 3
[2025-01-20 10:03:15] x --> (0, 10)
[2025-01-20 10:03:15] x_t --> tensor([[ 66,  67,  68,  70,  71],
        [142, 142, 144, 146, 146],
        [ 96,  98,  99, 100, 100]])
[2025-01-20 10:03:15] y --> (10, 20) 
[2025-01-20 10:03:15] y_t --> tensor([[ 75,  75,  76,  76,  77],
        [155, 158, 158, 159, 159],
        [107, 110, 111, 111, 114]]) 
[2025-01-20 10:03:15] f_pass_weights[0] ->, tensor([1., 1., 1.], device='cuda:0')
[2025-01-20 10:03:15] loss ->, 328.03692626953125
[2025-01-20 10:03:15] 

[2025-01-20 10:03:15] horizon --> 3
[2025-01-20 10:03:15] horizon_grad --> 3
[2025-01-20 10:03:15] x --> (10, 20)
[2025-01-20 10:03:15] x_t --> tensor([[ 75,  75,  76,  76,  77],
        [155, 158, 158, 159, 159],
        [107, 110, 111, 111, 114]])
[2025-01-20 10:03:15] y --> (20, 30) 
[2025-01-20 10:03:15] y_t --> tensor([[ 82,  85,  86,  86,  89],
        [164, 164, 164, 165, 168],
        [122, 122, 123, 124, 124]]) 
[2025-01-20 10:03:15] f_pass_weights[1] ->, tensor([1., 1., 1.], device='cuda:0')
[2025-01-20 10:03:15] loss ->, 658.1397705078125
[2025-01-20 10:03:15] 

[2025-01-20 10:03:15] horizon --> 3
[2025-01-20 10:03:15] horizon_grad --> 3
[2025-01-20 10:03:15] x --> (20, 30)
[2025-01-20 10:03:15] x_t --> tensor([[ 82,  85,  86,  86,  89],
        [164, 164, 164, 165, 168],
        [122, 122, 123, 124, 124]])
[2025-01-20 10:03:15] y --> (30, 40) 
[2025-01-20 10:03:15] y_t --> tensor([[ 95,  95,  96,  96,  98],
        [177, 182, 183, 183, 183],
        [136, 137, 138, 138, 139]]) 
[2025-01-20 10:03:15] f_pass_weights[2] ->, tensor([1., 1., 1.], device='cuda:0')
[2025-01-20 10:03:15] loss ->, 990.1702880859375
[2025-01-20 10:03:15] 

[2025-01-20 10:03:15] horizon --> 3
[2025-01-20 10:03:15] horizon_grad --> 3
[2025-01-20 10:03:15] x --> (0, 10)
[2025-01-20 10:03:15] x_t --> tensor([[155, 156, 157, 157, 158],
        [ 21,  23,  26,  28,  36],
        [ 11,  15,  15,  18,  21]])
[2025-01-20 10:03:15] y --> (10, 20) 
[2025-01-20 10:03:15] y_t --> tensor([[170, 170, 170, 171, 172],
        [ 63,  78,  83,  84,  85],
        [ 34,  36,  38,  48,  49]]) 
[2025-01-20 10:03:15] f_pass_weights[0] ->, tensor([1., 1., 1.], device='cuda:0')
[2025-01-20 10:03:15] loss ->, 325.7376403808594
[2025-01-20 10:03:15] 

[2025-01-20 10:03:15] horizon --> 3
[2025-01-20 10:03:15] horizon_grad --> 3
[2025-01-20 10:03:15] x --> (10, 20)
[2025-01-20 10:03:15] x_t --> tensor([[170, 170, 170, 171, 172],
        [ 63,  78,  83,  84,  85],
        [ 34,  36,  38,  48,  49]])
[2025-01-20 10:03:15] y --> (20, 30) 
[2025-01-20 10:03:15] y_t --> tensor([[177, 177, 177, 177, 177],
        [104, 107, 110, 114, 116],
        [ 71,  78,  80,  82,  88]]) 
[2025-01-20 10:03:15] f_pass_weights[1] ->, tensor([1., 1., 1.], device='cuda:0')
[2025-01-20 10:03:15] loss ->, 653.7249755859375
[2025-01-20 10:03:15] 

[2025-01-20 10:03:15] horizon --> 3
[2025-01-20 10:03:15] horizon_grad --> 3
[2025-01-20 10:03:15] x --> (20, 30)
[2025-01-20 10:03:15] x_t --> tensor([[177, 177, 177, 177, 177],
        [104, 107, 110, 114, 116],
        [ 71,  78,  80,  82,  88]])
[2025-01-20 10:03:15] y --> (30, 40) 
[2025-01-20 10:03:15] y_t --> tensor([[186, 187, 187, 187, 188],
        [132, 133, 136, 143, 145],
        [141, 142, 142, 143, 146]]) 
[2025-01-20 10:03:15] f_pass_weights[2] ->, tensor([1., 1., 1.], device='cuda:0')
[2025-01-20 10:03:15] loss ->, 983.6510009765625
[2025-01-20 10:03:15] 

[2025-01-20 10:03:15] horizon --> 3
[2025-01-20 10:03:15] horizon_grad --> 3
[2025-01-20 10:03:15] x --> (0, 10)
[2025-01-20 10:03:15] x_t --> tensor([[ 38,  38,  40,  41,  42],
        [ 19,  24,  24,  29,  29],
        [133, 134, 137, 137, 139]])
[2025-01-20 10:03:15] y --> (10, 20) 
[2025-01-20 10:03:15] y_t --> tensor([[ 51,  52,  52,  55,  55],
        [ 36,  36,  36,  38,  38],
        [144, 145, 147, 147, 149]]) 
[2025-01-20 10:03:15] f_pass_weights[0] ->, tensor([1., 1., 1.], device='cuda:0')
[2025-01-20 10:03:15] loss ->, 324.9727783203125
[2025-01-20 10:03:15] 

[2025-01-20 10:03:15] horizon --> 3
[2025-01-20 10:03:15] horizon_grad --> 3
[2025-01-20 10:03:15] x --> (10, 20)
[2025-01-20 10:03:15] x_t --> tensor([[ 51,  52,  52,  55,  55],
        [ 36,  36,  36,  38,  38],
        [144, 145, 147, 147, 149]])
[2025-01-20 10:03:15] y --> (20, 30) 
[2025-01-20 10:03:15] y_t --> tensor([[ 62,  64,  65,  66,  68],
        [ 47,  49,  49,  49,  51],
        [154, 154, 156, 156, 157]]) 
[2025-01-20 10:03:15] f_pass_weights[1] ->, tensor([1., 1., 1.], device='cuda:0')
[2025-01-20 10:03:15] loss ->, 652.2565307617188
[2025-01-20 10:03:15] 

[2025-01-20 10:03:15] horizon --> 3
[2025-01-20 10:03:15] horizon_grad --> 3
[2025-01-20 10:03:15] x --> (20, 30)
[2025-01-20 10:03:15] x_t --> tensor([[ 62,  64,  65,  66,  68],
        [ 47,  49,  49,  49,  51],
        [154, 154, 156, 156, 157]])
[2025-01-20 10:03:15] y --> (30, 40) 
[2025-01-20 10:03:15] y_t --> tensor([[ 73,  74,  75,  77,  78],
        [ 56,  57,  57,  59,  59],
        [168, 173, 173, 175, 176]]) 
[2025-01-20 10:03:15] f_pass_weights[2] ->, tensor([1., 1., 1.], device='cuda:0')
[2025-01-20 10:03:15] loss ->, 981.8401489257812
[2025-01-20 10:03:15] 

[2025-01-20 10:03:15] horizon --> 3
[2025-01-20 10:03:15] horizon_grad --> 3
[2025-01-20 10:03:15] x --> (0, 10)
[2025-01-20 10:03:15] x_t --> tensor([[61, 63, 65, 68, 73],
        [74, 76, 79, 79, 80],
        [36, 36, 36, 37, 40]])
[2025-01-20 10:03:15] y --> (10, 20) 
[2025-01-20 10:03:15] y_t --> tensor([[101, 106, 114, 117, 118],
        [ 90,  91,  91,  93,  96],
        [ 50,  51,  58,  68,  68]]) 
[2025-01-20 10:03:15] f_pass_weights[0] ->, tensor([1., 1., 1.], device='cuda:0')
[2025-01-20 10:03:15] loss ->, 327.193603515625
[2025-01-20 10:03:15] 

[2025-01-20 10:03:15] horizon --> 3
[2025-01-20 10:03:15] horizon_grad --> 3
[2025-01-20 10:03:15] x --> (10, 20)
[2025-01-20 10:03:15] x_t --> tensor([[101, 106, 114, 117, 118],
        [ 90,  91,  91,  93,  96],
        [ 50,  51,  58,  68,  68]])
[2025-01-20 10:03:15] y --> (20, 30) 
[2025-01-20 10:03:15] y_t --> tensor([[137, 147, 147, 156, 166],
        [107, 110, 112, 113, 115],
        [ 83,  83,  84,  85,  85]]) 
[2025-01-20 10:03:15] f_pass_weights[1] ->, tensor([1., 1., 1.], device='cuda:0')
[2025-01-20 10:03:15] loss ->, 657.3103637695312
[2025-01-20 10:03:15] 

[2025-01-20 10:03:15] horizon --> 3
[2025-01-20 10:03:15] horizon_grad --> 3
[2025-01-20 10:03:15] x --> (20, 30)
[2025-01-20 10:03:15] x_t --> tensor([[137, 147, 147, 156, 166],
        [107, 110, 112, 113, 115],
        [ 83,  83,  84,  85,  85]])
[2025-01-20 10:03:15] y --> (30, 40) 
[2025-01-20 10:03:15] y_t --> tensor([[178, 178, 181, 182, 183],
        [124, 126, 127, 131, 132],
        [ 96,  96,  98, 102, 103]]) 
[2025-01-20 10:03:15] f_pass_weights[2] ->, tensor([1., 1., 1.], device='cuda:0')
[2025-01-20 10:03:15] loss ->, 990.0765991210938
[2025-01-20 10:03:15] 

[2025-01-20 10:03:15] horizon --> 3
[2025-01-20 10:03:15] horizon_grad --> 3
[2025-01-20 10:03:15] x --> (0, 10)
[2025-01-20 10:03:15] x_t --> tensor([[144, 147, 148, 152, 154],
        [ 87,  87,  90,  92,  93],
        [148, 148, 150, 152, 152]])
[2025-01-20 10:03:15] y --> (10, 20) 
[2025-01-20 10:03:15] y_t --> tensor([[158, 160, 162, 162, 164],
        [106, 107, 108, 108, 110],
        [158, 159, 160, 160, 161]]) 
[2025-01-20 10:03:15] f_pass_weights[0] ->, tensor([1., 1., 1.], device='cuda:0')
[2025-01-20 10:03:15] loss ->, 326.1907958984375
[2025-01-20 10:03:15] 

[2025-01-20 10:03:15] horizon --> 3
[2025-01-20 10:03:15] horizon_grad --> 3
[2025-01-20 10:03:15] x --> (10, 20)
[2025-01-20 10:03:15] x_t --> tensor([[158, 160, 162, 162, 164],
        [106, 107, 108, 108, 110],
        [158, 159, 160, 160, 161]])
[2025-01-20 10:03:15] y --> (20, 30) 
[2025-01-20 10:03:15] y_t --> tensor([[179, 181, 183, 183, 184],
        [121, 123, 124, 126, 126],
        [164, 164, 165, 165, 165]]) 
[2025-01-20 10:03:15] f_pass_weights[1] ->, tensor([1., 1., 1.], device='cuda:0')
[2025-01-20 10:03:15] loss ->, 654.7258911132812
[2025-01-20 10:03:15] 

[2025-01-20 10:03:15] horizon --> 3
[2025-01-20 10:03:15] horizon_grad --> 3
[2025-01-20 10:03:15] x --> (20, 30)
[2025-01-20 10:03:15] x_t --> tensor([[179, 181, 183, 183, 184],
        [121, 123, 124, 126, 126],
        [164, 164, 165, 165, 165]])
[2025-01-20 10:03:15] y --> (30, 40) 
[2025-01-20 10:03:15] y_t --> tensor([[190, 193, 193, 193, 195],
        [143, 145, 147, 149, 153],
        [177, 178, 179, 181, 181]]) 
[2025-01-20 10:03:15] f_pass_weights[2] ->, tensor([1., 1., 1.], device='cuda:0')
[2025-01-20 10:03:15] loss ->, 985.278076171875
[2025-01-20 10:03:15] 

[2025-01-20 10:03:15] horizon --> 3
[2025-01-20 10:03:15] horizon_grad --> 3
[2025-01-20 10:03:15] x --> (0, 10)
[2025-01-20 10:03:15] x_t --> tensor([[53, 55, 57, 58, 60],
        [30, 30, 31, 34, 36],
        [35, 37, 40, 40, 45]])
[2025-01-20 10:03:15] y --> (10, 20) 
[2025-01-20 10:03:15] y_t --> tensor([[77, 79, 79, 79, 88],
        [47, 47, 48, 50, 52],
        [78, 79, 81, 81, 87]]) 
[2025-01-20 10:03:15] f_pass_weights[0] ->, tensor([1., 1., 1.], device='cuda:0')
[2025-01-20 10:03:15] loss ->, 324.4386291503906
[2025-01-20 10:03:15] 

[2025-01-20 10:03:15] horizon --> 3
[2025-01-20 10:03:15] horizon_grad --> 3
[2025-01-20 10:03:15] x --> (10, 20)
[2025-01-20 10:03:15] x_t --> tensor([[77, 79, 79, 79, 88],
        [47, 47, 48, 50, 52],
        [78, 79, 81, 81, 87]])
[2025-01-20 10:03:15] y --> (20, 30) 
[2025-01-20 10:03:15] y_t --> tensor([[113, 114, 121, 127, 128],
        [ 64,  65,  67,  69,  69],
        [104, 105, 109, 118, 119]]) 
[2025-01-20 10:03:15] f_pass_weights[1] ->, tensor([1., 1., 1.], device='cuda:0')
[2025-01-20 10:03:15] loss ->, 651.4163208007812
[2025-01-20 10:03:15] 

[2025-01-20 10:03:15] horizon --> 3
[2025-01-20 10:03:15] horizon_grad --> 3
[2025-01-20 10:03:15] x --> (20, 30)
[2025-01-20 10:03:15] x_t --> tensor([[113, 114, 121, 127, 128],
        [ 64,  65,  67,  69,  69],
        [104, 105, 109, 118, 119]])
[2025-01-20 10:03:15] y --> (30, 40) 
[2025-01-20 10:03:15] y_t --> tensor([[149, 156, 157, 159, 160],
        [ 78,  79,  79,  82,  84],
        [133, 133, 137, 140, 144]]) 
[2025-01-20 10:03:15] f_pass_weights[2] ->, tensor([1., 1., 1.], device='cuda:0')
[2025-01-20 10:03:15] loss ->, 980.5519409179688
[2025-01-20 10:03:15] 

[2025-01-20 10:03:26] TRAIN: ep: 1, time: 14.6994, lr: 0.001, TRAIN_CONST_OTO_250: 0.0000, TRAIN_CONST_RO_250: 0.0000, TRAIN_VAR_OTO_250: 0.0000, TRAIN_VAR_RO_250: 0.0000, TEST_VAR_OTO_250: 0.0000, TEST_VAR_RO_250: 0.0000
[2025-01-20 10:03:37] t_iter: 500/25000
[2025-01-20 10:03:37] f_pass_weights: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1.], device='cuda:0')
[2025-01-20 10:03:37] f_pass_weights_random: tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1.]], device='cuda:0')
[2025-01-20 10:03:37] 

[2025-01-20 10:03:37] TRAIN: ep: 2, time: 11.3307, lr: 0.001, TRAIN_CONST_OTO_250: 0.0000, TRAIN_CONST_RO_250: 0.0000, TRAIN_VAR_OTO_250: 0.0000, TRAIN_VAR_RO_250: 0.0000, TEST_VAR_OTO_250: 0.0000, TEST_VAR_RO_250: 0.0000
